{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92c0f035",
   "metadata": {},
   "source": [
    "## Podstawy Uczenia Maszynowego – Projekt\n",
    "### Rozpoznawanie nadużyć w transakcjach płatniczych na podstawie fizycznych okoliczności ich wykonania\n",
    "#### Autorzy: Kacper Korecki, Dominik Zakrzewski, Konrad Zbylut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57969e07",
   "metadata": {},
   "source": [
    "## Wprowadzenie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeecbc7",
   "metadata": {},
   "source": [
    "Celem naszego projektu jest analiza obszernego zbioru transakcji płatniczych za pomocą kilku wybranych algorytmów dla porównania ich charakterystyki i otrzymanych wyników."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44df9dbe",
   "metadata": {},
   "source": [
    "## O zbiorze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53267b35",
   "metadata": {},
   "source": [
    "Prezentowany przez nas zbiór danych \"card transaction data\" jest zbiorem przedstawiającym transakcje dokonywane kartami płatniczymi. Ilość rekordów w datasecie wynosi 1 000 000.\n",
    "\n",
    "Argumenty:\n",
    "* `distance_from_home` – odległość miejsca wykonania transakcji od adresu domowego klienta banku,\n",
    "* `distance_from_last_transaction` – odległość miejsca wykonania transakcji od miejsca poprzedniej transakcji,\n",
    "* `ratio_to_median_purchase_price` – stosunek wysokości kwoty transakcji do mediany wszystkich transakcji danego klienta,\n",
    "* `repeat_retailer` – argument logiczny (0.0/1.0) mówiący o tym, czy dany klient wykonywał już transakcję u danego sprzedającego,\n",
    "* `used_chip` – argument logiczny (0.0/1.0) mówiący o tym, czy przy transakcji została użyta karta (tj. czy faktycznie plastikowa karta została włożona np. do terminalu)\n",
    "* `used_pin_number` – argument logiczny (0.0/1.0) mówiący o tym, czy podczas transakcji został podany numer PIN,\n",
    "* `online_order` – argument logiczny (0.0/1.0) mówiący o tym, czy transakcja została wykonana przez Internet,\n",
    "\n",
    "Wynik:\n",
    "* `fraud` – argument logiczny (0.0/1.0) mówiący o tym, czy transakcja była nadużyciem (czyli np. została wykonana przez osobę, która włamała się na konto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3001d64",
   "metadata": {},
   "source": [
    "## Wczytanie i obróbka zbioru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42123dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b879d7",
   "metadata": {},
   "source": [
    "Wczytujemy zbiór danych z pliku CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ab979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('card_transdata.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5de3eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d62f5e",
   "metadata": {},
   "source": [
    "Ponadto sprawdzamy stosunek transakcji oznaczonych jako nadużycia (y=1.0) do liczby wszystkich transakcji w zbiorze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aebb3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_np = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200964f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_fraud_transactions = np.sum(data_np[:, 7])\n",
    "print(\"Percentage of fraud transactions:\", total_fraud_transactions / data_np.shape[0] * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83b1be5",
   "metadata": {},
   "source": [
    "Jak widzimy wyniki nie są zbyt \"różnorodne\", gdyż większość transakcji stanowią transakcje non-fraud. Ponadto liczba rekordów jest bardzo duża, więc na potrzeby prezentacji i ze względu na złożoność niektórych algorytmów (np. SVM) musimy zmniejszyć nieco liczbę rekordów. Stąd też przyszedł pomysł eksperymentu dostosowania zbioru tak by liczba transakcji \"normalnych\" była ograniczona tj. podobna do liczby transakcji oznaczonych jako nadużycia, a więc łącznie dostaniemy 160 000 transakcji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb8f485",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = data_np[:, :-1]\n",
    "y_raw = data_np[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6656ef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "#X_raw = StandardScaler().fit_transform(X_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b885c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "non_fraud_limit = 85000\n",
    "non_fraud_c = 0\n",
    "\n",
    "for i in range(len(X_raw)):\n",
    "    if y_raw[i] == 0.0 and non_fraud_c <= non_fraud_limit:\n",
    "        X.append(X_raw[i])\n",
    "        y.append(y_raw[i])\n",
    "        non_fraud_c += 1\n",
    "    elif y_raw[i] == 1.0:\n",
    "        X.append(X_raw[i])\n",
    "        y.append(y_raw[i])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5af75d",
   "metadata": {},
   "source": [
    "Dokonujemy podziału na zbiory X i y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9b72e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_raw, y_raw, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2832e3",
   "metadata": {},
   "source": [
    "A także przygotowujemy funkcję pomocniczą przy rysowaniu macierzy pomyłek:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f7eb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "def confusion_matrix_from_preds(model, title):\n",
    "    preds = model.predict(X_test)\n",
    "    cm = ConfusionMatrixDisplay.from_predictions(y_test, preds)\n",
    "    cm.ax_.set_title(title)\n",
    "    plt.show()\n",
    "    print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6258f7d8",
   "metadata": {},
   "source": [
    "## Naiwny klasyfikator Bayesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c677bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, ComplementNB, BernoulliNB, MultinomialNB\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5941218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_nb_model = GaussianNB().fit(X_train, y_train)\n",
    "\n",
    "gaussian_nb_train_sc = gaussian_nb_model.score(X_train, y_train)\n",
    "gaussian_nb_test_sc = gaussian_nb_model.score(X_test, y_test)\n",
    "\n",
    "confusion_matrix_from_preds(gaussian_nb_model, 'Gaussian NB Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d97dad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "complement_nb_model = ComplementNB().fit(X_train, y_train)\n",
    "\n",
    "complement_nb_train_sc = complement_nb_model.score(X_train, y_train)\n",
    "complement_nb_test_sc = complement_nb_model.score(X_test, y_test)\n",
    "\n",
    "confusion_matrix_from_preds(complement_nb_model, 'Complement NB Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe7fabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bernoulli_nb_model = BernoulliNB().fit(X_train, y_train)\n",
    "\n",
    "bernoulli_nb_train_sc = bernoulli_nb_model.score(X_train, y_train)\n",
    "bernoulli_nb_test_sc = bernoulli_nb_model.score(X_test, y_test)\n",
    "\n",
    "confusion_matrix_from_preds(bernoulli_nb_model, 'Bernoulli NB Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c94f320",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multinomial_nb_model = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "multinomial_nb_train_sc = multinomial_nb_model.score(X_train, y_train)\n",
    "multinomial_nb_test_sc = multinomial_nb_model.score(X_test, y_test)\n",
    "\n",
    "confusion_matrix_from_preds(multinomial_nb_model, 'Multinomial NB Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ded398",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adf1000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2f051e",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = svm.SVC(kernel='rbf', verbose=True).fit(X_train, y_train)\n",
    "preds = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf75285",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_from_preds(svm_model, 'SVM Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b41ae5c",
   "metadata": {},
   "source": [
    "### SVM with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d622ec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9194995",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = svm.SVC( verbose=True)\n",
    "params = {\n",
    "    'kernel': ['rbf', 'poly'],\n",
    "    'C': [1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "rs = RandomizedSearchCV(svm_model, params, cv=3, verbose=2)\n",
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ecf0de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix_from_preds(rs, 'SVM with RS Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239ac72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Najlepsze parametry: {rs.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c085ac0",
   "metadata": {},
   "source": [
    "Niestety algorytm ten dla dużej ilości danych w naszym przypadku się nie sprawdzi, gdyż jego złożoność obliczeniowa oznacza wiele godzin oczekiwania na wynik, który możemy osiągnąć innymi metodami."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b06afd6",
   "metadata": {},
   "source": [
    "## Drzewa decyzyjne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92f2d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0f3ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier = tree.DecisionTreeClassifier(random_state=1)\n",
    "dt_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3024cc7c",
   "metadata": {},
   "source": [
    "Wyświetlamy głębokość drzewa, dla której klasyfikator osiąga najlepsze wyniki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef27302",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dt_classifier.get_depth())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d097eb99",
   "metadata": {},
   "source": [
    "Ponadto wyświetlamy tablicę feature importances, czyli istotności poszczególnych argumentów dla działania modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4f4b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dt_classifier.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bb2621",
   "metadata": {},
   "source": [
    "Chcielibyśmy też zobaczyć wykres przedstawiający zależność głębokości od osiąganych wyników"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293dff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers, scores_train, scores_test = [], [], []\n",
    "depths = np.arange(2, 15)\n",
    "\n",
    "for depth in depths:\n",
    "    classifier = tree.DecisionTreeClassifier(random_state=0, max_depth=depth)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    classifiers.append(classifier)\n",
    "\n",
    "    scores_train.append(classifier.score(X_train, y_train))\n",
    "    scores_test.append(classifier.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0927e420",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(depths, scores_train, c='b', label='train')\n",
    "plt.plot(depths, scores_test, c='r', label='test')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "best = 2 + np.argmax(scores_test)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1790c23f",
   "metadata": {},
   "source": [
    "Interesuje nas też rozkład poszczególnych przypadków testowych, dlatego rysujemy macierz pomyłek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f00496",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_from_preds(dt_classifier, 'Decision Tree Classifier Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584fe020",
   "metadata": {},
   "source": [
    "## Analiza najlepszego modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ea8e65",
   "metadata": {},
   "source": [
    "Po wybraniu najlepszego modelu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d590e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_classifier = dt_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963cc205",
   "metadata": {},
   "source": [
    "Możemy przejść do jego analizy, np. poprzez ręczne symulowanie transakcji i sprawdzanie wyników. W tym celu wykorzystamy widżety jupytera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5f673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5f5abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(distance_from_home, distance_from_last_transaction, ratio_to_median_purchase_price, repeat_retailer, used_chip, used_pin_number, online_order):\n",
    "    res = best_classifier.predict(np.array([[distance_from_home, distance_from_last_transaction, ratio_to_median_purchase_price, repeat_retailer, used_chip, used_pin_number, online_order]]))\n",
    "    y = res[0]\n",
    "    if y == 0.0:\n",
    "        return \"Transaction is not a fraud\"\n",
    "    else:\n",
    "        return \"Transaction is FRAUD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25fb6ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w = interact(f, distance_from_home=widgets.FloatSlider(min=0.0, max=500.0, step=1.0), distance_from_last_transaction=widgets.FloatSlider(min=0.0, max=500.0, step=1.0), ratio_to_median_purchase_price=widgets.FloatSlider(min=0.0, max=10.0, step=0.1), repeat_retailer=True, used_chip=False, used_pin_number=False, online_order=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c231589",
   "metadata": {},
   "source": [
    "### Podgląd drzewa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f884ddc4",
   "metadata": {},
   "source": [
    "Ponadto algorytm drzew decyzyjnych jest algorytmem \"white box\", czyli takim, którego działanie możemy prześledzić. W tym celu wydrukujemy sobie drzewo do pliku graficznego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276f7877",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(30, 10), dpi=600)\n",
    "tree.plot_tree(best_classifier)\n",
    "\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a157f36",
   "metadata": {},
   "source": [
    "### Test wszystkiego"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e466bdb1",
   "metadata": {},
   "source": [
    "Na koniec możemy także sprawdzić dokładność działania modelu na całym zbiorze, który posiadamy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6292e75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_classifier.score(X_raw, y_raw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
